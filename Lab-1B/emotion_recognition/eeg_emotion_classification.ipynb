{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion recognition using EEG and computer games (+micro:bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oEGRdjhQEijp"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import os\n",
    "\n",
    "# Constants\n",
    "SAMPLE_RATE = 32 # (Hz)\n",
    "GAMES = [\"boring\", \"calm\", \"horror\", \"funny\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFO1TlCsJ1EJ"
   },
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read and plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MM8kVtV7E66K"
   },
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data = []\n",
    "for game_id, game in enumerate(GAMES):\n",
    "    game_data = pd.read_csv(os.path.join(\"data\", f\"S01G{game_id + 1}AllChannels.csv\"))\n",
    "    game_data[\"game\"] = game\n",
    "    data.append(game_data)\n",
    "\n",
    "data = pd.concat(data, axis = 0, ignore_index = True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "vQZOrf6gFAmQ",
    "outputId": "1d78376f-11ff-4f80-be16-ed5490e09420"
   },
   "outputs": [],
   "source": [
    "# TODO: choose one of the frontal (F3 / F4 / F7 / F8 / FC5 / FC6) or temporal (T7 / T8) electrodes and ensure the signal is clean\n",
    "electrode = \"T7\"\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for game in GAMES:\n",
    "    ax.plot(data[data[\"game\"] == game][electrode], label = game)\n",
    "ax.set_xlabel(\"Time (seconds)\")\n",
    "ax.set_xticks(range(0, len(data), SAMPLE_RATE * 60 * 10))\n",
    "ax.set_ylabel(\"mV\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the chosen electrode and create a dataset of X-second clips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: re-reference the data if needed\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[electrode, \"game\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_uZIIhyHjPV"
   },
   "outputs": [],
   "source": [
    "# TODO: adjust if needed\n",
    "clip_length = 2 # (seconds)\n",
    "\n",
    "# Split into clips\n",
    "clipped_data = []\n",
    "y = []\n",
    "for game_id, game in enumerate(GAMES):\n",
    "    clips = np.array_split(\n",
    "        data[data['game'] == game][electrode].to_numpy(), \n",
    "        len(data[data['game'] == game]) // (clip_length * SAMPLE_RATE))\n",
    "    clipped_data.extend(clips)\n",
    "    y.extend([game_id] * len(clips))\n",
    "\n",
    "# Remove edge effects\n",
    "min_length = np.min([len(arr) for arr in clipped_data])\n",
    "X = []\n",
    "for array in clipped_data:\n",
    "    X.append(array[:min_length])\n",
    "\n",
    "X = np.vstack(X, dtype = float)\n",
    "y = np.array(y, dtype = int)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qn-ylcgyJw3T"
   },
   "source": [
    "## Train a CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gyZo0z1PJTas"
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# Add an additional axis required by torch's Conv layers\n",
    "X = np.expand_dims(X, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_train, X_test = torch.Tensor(X_train), torch.Tensor(X_test)\n",
    "y_train, y_test = torch.Tensor(y_train), torch.Tensor(y_test)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RH4CJyj4J4pO"
   },
   "outputs": [],
   "source": [
    "class LFPDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y.long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6FRgyW3RJ6XN"
   },
   "outputs": [],
   "source": [
    "# Batch generators\n",
    "\n",
    "# TODO: adjust if needed\n",
    "batch_size = 32\n",
    "\n",
    "train_batch_generator = torch.utils.data.DataLoader(LFPDataset(X_train, y_train), batch_size = batch_size,\n",
    "                                                    shuffle = True)\n",
    "\n",
    "test_batch_generator = torch.utils.data.DataLoader(LFPDataset(X_test, y_test), batch_size = batch_size,\n",
    "                                                    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h9zZwnttJ9NZ"
   },
   "outputs": [],
   "source": [
    "# TODO: adjust if needed\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv1d(1, 1, kernel_size = 4, padding = \"same\"),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv1d(1, 1, kernel_size = 4, padding = \"same\"),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(64, 4),\n",
    "    torch.nn.LogSoftmax(dim = 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lt5XTGhKKAbY"
   },
   "outputs": [],
   "source": [
    "def train(n_epoch, model):\n",
    "    # TODO: adjust learning rate if needed\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "    for e in range(n_epoch):\n",
    "        model.train(True)\n",
    "\n",
    "        train_loss = []\n",
    "        train_acc = []\n",
    "        for X_batch, y_batch in train_batch_generator:\n",
    "            model.zero_grad()\n",
    "            logits = model(X_batch).squeeze()\n",
    "            loss = torch.nn.functional.nll_loss(logits, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.detach().numpy())\n",
    "            \n",
    "            prediction = torch.softmax(logits, dim = 1).detach().numpy()\n",
    "            prediction = np.argmax(prediction, axis = 1)\n",
    "            train_acc.append(accuracy_score(y_batch.detach().numpy(), prediction))\n",
    "\n",
    "        model.train(False)\n",
    "        test_loss = []\n",
    "        test_acc = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_batch_generator:\n",
    "                logits = model(X_batch).squeeze()\n",
    "                loss = torch.nn.functional.nll_loss(logits, y_batch)\n",
    "                test_loss.append(loss.detach().numpy())\n",
    "\n",
    "                prediction = torch.softmax(logits, dim = 1).detach().numpy()\n",
    "                prediction = np.argmax(prediction, axis = 1)\n",
    "                test_acc.append(accuracy_score(y_batch.detach().numpy(), prediction))\n",
    "\n",
    "        print(f\"Epoch {e} : train_loss={np.mean(train_loss)}, train_acc={np.mean(train_acc)}, test_loss={np.mean(test_loss)}, test_acc={np.mean(test_acc)}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5iN00ZmuKF49",
    "outputId": "f0af20c0-4ca4-44c2-bf34-4c50a60198ae"
   },
   "outputs": [],
   "source": [
    "train(n_epoch = 100, model = model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prediction and project to the micro:bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5iWRV_jfKLYx"
   },
   "outputs": [],
   "source": [
    "a_clip = X[0]\n",
    "plt.plot(a_clip.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(torch.tensor(np.expand_dims(a_clip, 1)).float())\n",
    "prediction = torch.softmax(prediction, dim = 1).detach().numpy()\n",
    "prediction = int(np.argmax(prediction, axis = 1)[0])\n",
    "\n",
    "GAMES[prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code for projecting to the micro:bit\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
